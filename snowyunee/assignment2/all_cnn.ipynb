{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras CIFAR10をCNNで分類\n",
    "\n",
    "この論文のAll-CNN-Cをやってみた\n",
    "http://arxiv.org/pdf/1412.6806.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://gist.github.com/juntaki/e50200c82d6f3a5143e7b206a0ab2451\n",
    "# https://github.com/NervanaSystems/neon/blob/master/examples/cifar10_allcnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import *\n",
    "from sklearn import datasets, preprocessing\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train shape:', (50000, 3, 32, 32))\n",
      "(50000, 'train samples')\n",
      "(10000, 'test samples')\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_classes = 10\n",
    "nb_epoch = 10\n",
    "data_augmentation = True\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "# the CIFAR10 images are RGB\n",
    "img_channels = 3\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD9CAYAAACcAsr/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4cc15c4a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "number = 404\n",
    "img = X_train[number].reshape(3,32,32)\n",
    "img1 = np.rollaxis(img, 0 ,3)\n",
    "img1.shape\n",
    "plt.imshow(img1, interpolation='none')\n",
    "Y_train[number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dropout_51 (Dropout)             (None, 3, 32, 32)     0           dropout_input_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_154 (Convolution2D)(None, 96, 32, 32)    2688        dropout_51[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_171 (Activation)      (None, 96, 32, 32)    0           convolution2d_154[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_155 (Convolution2D)(None, 96, 32, 32)    83040       activation_171[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_172 (Activation)      (None, 96, 32, 32)    0           convolution2d_155[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_156 (Convolution2D)(None, 96, 16, 16)    83040       activation_172[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_173 (Activation)      (None, 96, 16, 16)    0           convolution2d_156[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)             (None, 96, 16, 16)    0           activation_173[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_157 (Convolution2D)(None, 192, 16, 16)   166080      dropout_52[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_174 (Activation)      (None, 192, 16, 16)   0           convolution2d_157[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_158 (Convolution2D)(None, 192, 16, 16)   331968      activation_174[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_175 (Activation)      (None, 192, 16, 16)   0           convolution2d_158[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_159 (Convolution2D)(None, 192, 8, 8)     331968      activation_175[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_176 (Activation)      (None, 192, 8, 8)     0           convolution2d_159[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)             (None, 192, 8, 8)     0           activation_176[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_160 (Convolution2D)(None, 192, 8, 8)     331968      dropout_53[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_177 (Activation)      (None, 192, 8, 8)     0           convolution2d_160[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_161 (Convolution2D)(None, 192, 8, 8)     37056       activation_177[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_178 (Activation)      (None, 192, 8, 8)     0           convolution2d_161[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_162 (Convolution2D)(None, 10, 8, 8)      1930        activation_178[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_179 (Activation)      (None, 10, 8, 8)      0           convolution2d_162[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_18 (AveragePooli(None, 10, 1, 1)      0           activation_179[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)             (None, 10)            0           averagepooling2d_18[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_180 (Activation)      (None, 10)            0           flatten_18[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1369738\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dropout(0.2, input_shape=(3, 32, 32)))\n",
    "model.add(Convolution2D(96, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001) ))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(96, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(96, 3, 3, border_mode=\"same\", subsample=(2,2), W_regularizer=l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(192, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(192, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(192, 3, 3, border_mode=\"same\", subsample=(2,2), W_regularizer=l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(192, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(192, 1, 1, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(10, 1, 1, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D(pool_size=(8, 8), border_mode='valid'))\n",
    "model.add(Flatten())\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "#op = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=op, metrics=['accuracy'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adadelta\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 111s - loss: 0.3111 - acc: 0.8925 - val_loss: 0.5782 - val_acc: 0.8121\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 110s - loss: 0.2975 - acc: 0.8956 - val_loss: 0.6200 - val_acc: 0.8118\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 111s - loss: 0.2955 - acc: 0.8960 - val_loss: 0.6222 - val_acc: 0.8001\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 111s - loss: 0.2837 - acc: 0.9002 - val_loss: 0.5842 - val_acc: 0.8134\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 110s - loss: 0.2723 - acc: 0.9052 - val_loss: 0.5725 - val_acc: 0.8201\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 110s - loss: 0.2674 - acc: 0.9055 - val_loss: 0.5690 - val_acc: 0.8195\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 110s - loss: 0.2608 - acc: 0.9089 - val_loss: 0.6147 - val_acc: 0.8085\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 110s - loss: 0.2578 - acc: 0.9095 - val_loss: 0.5658 - val_acc: 0.8225\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 110s - loss: 0.2447 - acc: 0.9123 - val_loss: 0.6447 - val_acc: 0.8089\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 111s - loss: 0.2405 - acc: 0.9167 - val_loss: 0.6181 - val_acc: 0.8139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4d0d49a150>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        samples_per_epoch=X_train.shape[0],\n",
    "                        nb_epoch=nb_epoch,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 111s - loss: 0.5089 - acc: 0.8258 - val_loss: 0.6287 - val_acc: 0.7854\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 110s - loss: 0.4826 - acc: 0.8333 - val_loss: 0.5982 - val_acc: 0.7973\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 110s - loss: 0.4597 - acc: 0.8402 - val_loss: 0.7436 - val_acc: 0.7491\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 110s - loss: 0.4393 - acc: 0.8473 - val_loss: 0.6234 - val_acc: 0.7918\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 110s - loss: 0.4190 - acc: 0.8532 - val_loss: 0.6460 - val_acc: 0.7916\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 110s - loss: 0.4032 - acc: 0.8592 - val_loss: 0.6062 - val_acc: 0.7997\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 110s - loss: 0.3864 - acc: 0.8645 - val_loss: 0.6143 - val_acc: 0.7883\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 111s - loss: 0.3721 - acc: 0.8699 - val_loss: 0.5927 - val_acc: 0.7998\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 110s - loss: 0.3578 - acc: 0.8767 - val_loss: 0.5717 - val_acc: 0.8080\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 110s - loss: 0.3424 - acc: 0.8802 - val_loss: 0.6033 - val_acc: 0.8056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4d0d645c50>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        samples_per_epoch=X_train.shape[0],\n",
    "                        nb_epoch=nb_epoch,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26176/50000 [==============>...............] - ETA: 50s - loss: 0.3080 - acc: 0.8934"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-ab150a6c6c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                         validation_data=(X_test, Y_test))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1443\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1444\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1445\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1446\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1221\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 372\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    373\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 636\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    637\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 708\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    709\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    713\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    695\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    696\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        samples_per_epoch=X_train.shape[0],\n",
    "                        nb_epoch=100,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_model (optimizer):\n",
    "  model = Sequential()\n",
    "  model.add(Dropout(0.2, input_shape=(3, 32, 32)))\n",
    "  model.add(Convolution2D(96, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001) ))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(96, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(96, 3, 3, border_mode=\"same\", subsample=(2,2), W_regularizer=l2(0.001)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Convolution2D(192, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(192, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(192, 3, 3, border_mode=\"same\", subsample=(2,2), W_regularizer=l2(0.001)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Convolution2D(192, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(192, 1, 1, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(10, 1, 1, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(AveragePooling2D(pool_size=(8, 8), border_mode='valid'))\n",
    "  model.add(Flatten())\n",
    "  model.add(Activation(\"softmax\"))\n",
    "\n",
    "  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "  model.summary()\n",
    "  return model\n",
    "\n",
    "def make_detagen ():\n",
    "  datagen = ImageDataGenerator(\n",
    "          featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "          samplewise_center=False,  # set each sample mean to 0\n",
    "          featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "          samplewise_std_normalization=False,  # divide each input by its std\n",
    "          zca_whitening=False,  # apply ZCA whitening\n",
    "          rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "          width_shift_range=0.,  # randomly shift images horizontally (fraction of total width)\n",
    "          height_shift_range=0.,  # randomly shift images vertically (fraction of total height)\n",
    "          horizontal_flip=False,  # randomly flip images\n",
    "          vertical_flip=False)  # randomly flip images\n",
    "\n",
    "  datagen.fit(X_train)\n",
    "  return datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dropout_60 (Dropout)             (None, 3, 32, 32)     0           dropout_input_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_181 (Convolution2D)(None, 96, 32, 32)    2688        dropout_60[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_201 (Activation)      (None, 96, 32, 32)    0           convolution2d_181[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_182 (Convolution2D)(None, 96, 32, 32)    83040       activation_201[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_202 (Activation)      (None, 96, 32, 32)    0           convolution2d_182[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_183 (Convolution2D)(None, 96, 16, 16)    83040       activation_202[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_203 (Activation)      (None, 96, 16, 16)    0           convolution2d_183[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)             (None, 96, 16, 16)    0           activation_203[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_184 (Convolution2D)(None, 192, 16, 16)   166080      dropout_61[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_204 (Activation)      (None, 192, 16, 16)   0           convolution2d_184[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_185 (Convolution2D)(None, 192, 16, 16)   331968      activation_204[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_205 (Activation)      (None, 192, 16, 16)   0           convolution2d_185[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_186 (Convolution2D)(None, 192, 8, 8)     331968      activation_205[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_206 (Activation)      (None, 192, 8, 8)     0           convolution2d_186[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)             (None, 192, 8, 8)     0           activation_206[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_187 (Convolution2D)(None, 192, 8, 8)     331968      dropout_62[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_207 (Activation)      (None, 192, 8, 8)     0           convolution2d_187[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_188 (Convolution2D)(None, 192, 8, 8)     37056       activation_207[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_208 (Activation)      (None, 192, 8, 8)     0           convolution2d_188[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_189 (Convolution2D)(None, 10, 8, 8)      1930        activation_208[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_209 (Activation)      (None, 10, 8, 8)      0           convolution2d_189[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_21 (AveragePooli(None, 10, 1, 1)      0           activation_209[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)             (None, 10)            0           averagepooling2d_21[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_210 (Activation)      (None, 10)            0           flatten_21[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1369738\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "37696/50000 [=====================>........] - ETA: 24s - loss: 2.2543 - acc: 0.1498"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-9cec0924e90d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                         \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                         \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                         validation_data=(X_test, Y_test))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1443\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1444\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1445\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1446\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1221\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 372\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    373\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 636\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    637\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 708\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    709\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    713\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    695\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    696\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#op = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "op = SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model2 = make_model(\"sgd\")\n",
    "datagen2 = make_detagen()\n",
    "model2.fit_generator(datagen2.flow(X_train, Y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        samples_per_epoch=X_train.shape[0],\n",
    "                        nb_epoch=nb_epoch,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 106s - loss: 2.1376 - acc: 0.2253 - val_loss: 1.9873 - val_acc: 0.2958\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 105s - loss: 1.9683 - acc: 0.2983 - val_loss: 1.9630 - val_acc: 0.2874\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 105s - loss: 1.8239 - acc: 0.3598 - val_loss: 1.7261 - val_acc: 0.3978\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 105s - loss: 1.7311 - acc: 0.4017 - val_loss: 1.6492 - val_acc: 0.4289\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 105s - loss: 1.5877 - acc: 0.4316 - val_loss: 1.6507 - val_acc: 0.4034\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 105s - loss: 1.4784 - acc: 0.4657 - val_loss: 1.4966 - val_acc: 0.4373\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 105s - loss: 1.4114 - acc: 0.4915 - val_loss: 1.3984 - val_acc: 0.4823\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 105s - loss: 1.3450 - acc: 0.5162 - val_loss: 1.2984 - val_acc: 0.5377\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 105s - loss: 1.2911 - acc: 0.5365 - val_loss: 1.3983 - val_acc: 0.5019\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 105s - loss: 1.2324 - acc: 0.5614 - val_loss: 1.3254 - val_acc: 0.5407\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 105s - loss: 1.1804 - acc: 0.5789 - val_loss: 1.3178 - val_acc: 0.5451\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 105s - loss: 1.1171 - acc: 0.6034 - val_loss: 1.2207 - val_acc: 0.5954\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 105s - loss: 1.0706 - acc: 0.6229 - val_loss: 1.2727 - val_acc: 0.5829\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 105s - loss: 1.0258 - acc: 0.6386 - val_loss: 1.1090 - val_acc: 0.6270\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.9851 - acc: 0.6534 - val_loss: 1.1151 - val_acc: 0.6171\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.9484 - acc: 0.6654 - val_loss: 1.0623 - val_acc: 0.6533\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.9137 - acc: 0.6806 - val_loss: 1.0426 - val_acc: 0.6713\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.8825 - acc: 0.6913 - val_loss: 1.0502 - val_acc: 0.6513\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.8455 - acc: 0.7034 - val_loss: 1.0032 - val_acc: 0.6698\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.8223 - acc: 0.7119 - val_loss: 0.9386 - val_acc: 0.6933\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.7967 - acc: 0.7234 - val_loss: 0.9925 - val_acc: 0.6892\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.7725 - acc: 0.7313 - val_loss: 0.9909 - val_acc: 0.6766\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.7486 - acc: 0.7388 - val_loss: 0.9142 - val_acc: 0.6981\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.7268 - acc: 0.7462 - val_loss: 0.9436 - val_acc: 0.7103\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.7038 - acc: 0.7556 - val_loss: 0.8900 - val_acc: 0.6965\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.6866 - acc: 0.7600 - val_loss: 0.8364 - val_acc: 0.7265\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.6645 - acc: 0.7688 - val_loss: 0.9013 - val_acc: 0.6810\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.6500 - acc: 0.7736 - val_loss: 0.7865 - val_acc: 0.7445\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.6276 - acc: 0.7813 - val_loss: 0.8172 - val_acc: 0.7416\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.6114 - acc: 0.7889 - val_loss: 0.7719 - val_acc: 0.7445\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.5994 - acc: 0.7931 - val_loss: 0.7879 - val_acc: 0.7377\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.5858 - acc: 0.7965 - val_loss: 0.6970 - val_acc: 0.7753\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.5678 - acc: 0.8016 - val_loss: 0.8156 - val_acc: 0.7302\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.5547 - acc: 0.8070 - val_loss: 0.6792 - val_acc: 0.7721\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.5431 - acc: 0.8115 - val_loss: 0.7000 - val_acc: 0.7770\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.5324 - acc: 0.8158 - val_loss: 0.6438 - val_acc: 0.7869\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.5169 - acc: 0.8179 - val_loss: 0.7078 - val_acc: 0.7715\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.5071 - acc: 0.8228 - val_loss: 0.7059 - val_acc: 0.7650\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.4965 - acc: 0.8261 - val_loss: 0.6814 - val_acc: 0.7690\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.4843 - acc: 0.8287 - val_loss: 0.6656 - val_acc: 0.7819\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.4723 - acc: 0.8346 - val_loss: 0.6678 - val_acc: 0.7837\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.4628 - acc: 0.8382 - val_loss: 0.6246 - val_acc: 0.7950\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.4604 - acc: 0.8384 - val_loss: 0.6990 - val_acc: 0.7737\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.4483 - acc: 0.8441 - val_loss: 0.6831 - val_acc: 0.7699\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.4328 - acc: 0.8499 - val_loss: 0.6662 - val_acc: 0.7775\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.4248 - acc: 0.8515 - val_loss: 0.5951 - val_acc: 0.8090\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.4177 - acc: 0.8511 - val_loss: 0.6519 - val_acc: 0.7772\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.4118 - acc: 0.8568 - val_loss: 0.6222 - val_acc: 0.7913\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.4014 - acc: 0.8588 - val_loss: 0.5929 - val_acc: 0.8039\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.3917 - acc: 0.8611 - val_loss: 0.5641 - val_acc: 0.8127\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.3855 - acc: 0.8648 - val_loss: 0.6539 - val_acc: 0.7859\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.3836 - acc: 0.8652 - val_loss: 0.6084 - val_acc: 0.7963\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.3712 - acc: 0.8686 - val_loss: 0.6066 - val_acc: 0.7933\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.3638 - acc: 0.8721 - val_loss: 0.6371 - val_acc: 0.7761\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.3573 - acc: 0.8755 - val_loss: 0.6031 - val_acc: 0.7995\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.3447 - acc: 0.8783 - val_loss: 0.5591 - val_acc: 0.8100\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.3423 - acc: 0.8789 - val_loss: 0.5499 - val_acc: 0.8132\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.3371 - acc: 0.8817 - val_loss: 0.6648 - val_acc: 0.7709\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.3304 - acc: 0.8839 - val_loss: 0.5791 - val_acc: 0.8052\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.3188 - acc: 0.8889 - val_loss: 0.5415 - val_acc: 0.8191\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.3214 - acc: 0.8860 - val_loss: 0.5773 - val_acc: 0.8063\n",
      "Epoch 62/100\n",
      "47712/50000 [===========================>..] - ETA: 4s - loss: 0.3120 - acc: 0.8903"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-3aa20c262316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                         validation_data=(X_test, Y_test))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1453\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m                 \u001b[0;31m# construct epoch logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# will be handled by on_epoch_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nb_sample'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/utils/generic_utils.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, force)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/iostream.pyc\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mevt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2.fit_generator(datagen.flow(X_train, Y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        samples_per_epoch=X_train.shape[0],\n",
    "                        nb_epoch=100,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.3051 - acc: 0.8924 - val_loss: 0.6202 - val_acc: 0.7929\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.3036 - acc: 0.8931 - val_loss: 0.5756 - val_acc: 0.8044\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2958 - acc: 0.8960 - val_loss: 0.5842 - val_acc: 0.8001\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2888 - acc: 0.8973 - val_loss: 0.5536 - val_acc: 0.8118\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2895 - acc: 0.8969 - val_loss: 0.5998 - val_acc: 0.7966\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2817 - acc: 0.9000 - val_loss: 0.6315 - val_acc: 0.7884\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2765 - acc: 0.9008 - val_loss: 0.5418 - val_acc: 0.8208\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2675 - acc: 0.9050 - val_loss: 0.5932 - val_acc: 0.8050\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2675 - acc: 0.9047 - val_loss: 0.5789 - val_acc: 0.8054\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2681 - acc: 0.9043 - val_loss: 0.5542 - val_acc: 0.8141\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2620 - acc: 0.9069 - val_loss: 0.5543 - val_acc: 0.8119\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2563 - acc: 0.9098 - val_loss: 0.5326 - val_acc: 0.8211\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2557 - acc: 0.9094 - val_loss: 0.5407 - val_acc: 0.8142\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2510 - acc: 0.9097 - val_loss: 0.6495 - val_acc: 0.7760\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2431 - acc: 0.9143 - val_loss: 0.5223 - val_acc: 0.8291\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2387 - acc: 0.9142 - val_loss: 0.5273 - val_acc: 0.8252\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2401 - acc: 0.9149 - val_loss: 0.6879 - val_acc: 0.7685\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2307 - acc: 0.9175 - val_loss: 0.5365 - val_acc: 0.8196\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2307 - acc: 0.9179 - val_loss: 0.5859 - val_acc: 0.8071\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2249 - acc: 0.9200 - val_loss: 0.5093 - val_acc: 0.8261\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2203 - acc: 0.9214 - val_loss: 0.5328 - val_acc: 0.8265\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2141 - acc: 0.9238 - val_loss: 0.5974 - val_acc: 0.8050\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2161 - acc: 0.9236 - val_loss: 0.5547 - val_acc: 0.8141\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2137 - acc: 0.9229 - val_loss: 0.5928 - val_acc: 0.8002\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2103 - acc: 0.9258 - val_loss: 0.5668 - val_acc: 0.8126\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2062 - acc: 0.9272 - val_loss: 0.5434 - val_acc: 0.8211\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2000 - acc: 0.9276 - val_loss: 0.5764 - val_acc: 0.8160\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.2027 - acc: 0.9281 - val_loss: 0.5511 - val_acc: 0.8211\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1949 - acc: 0.9317 - val_loss: 0.5673 - val_acc: 0.8161\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1972 - acc: 0.9313 - val_loss: 0.5363 - val_acc: 0.8285\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1936 - acc: 0.9317 - val_loss: 0.5246 - val_acc: 0.8267\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1873 - acc: 0.9316 - val_loss: 0.5350 - val_acc: 0.8251\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1911 - acc: 0.9301 - val_loss: 0.5688 - val_acc: 0.8181\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1912 - acc: 0.9315 - val_loss: 0.5671 - val_acc: 0.8159\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1855 - acc: 0.9331 - val_loss: 0.6813 - val_acc: 0.7877\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1802 - acc: 0.9361 - val_loss: 0.5336 - val_acc: 0.8282\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1786 - acc: 0.9372 - val_loss: 0.5258 - val_acc: 0.8296\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1815 - acc: 0.9351 - val_loss: 0.5358 - val_acc: 0.8313\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1709 - acc: 0.9394 - val_loss: 0.5163 - val_acc: 0.8367\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1751 - acc: 0.9383 - val_loss: 0.5218 - val_acc: 0.8300\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1721 - acc: 0.9395 - val_loss: 0.5301 - val_acc: 0.8311\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1702 - acc: 0.9391 - val_loss: 0.5420 - val_acc: 0.8283\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1694 - acc: 0.9403 - val_loss: 0.5950 - val_acc: 0.8091\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1658 - acc: 0.9415 - val_loss: 0.5242 - val_acc: 0.8329\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1622 - acc: 0.9433 - val_loss: 0.5491 - val_acc: 0.8298\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1616 - acc: 0.9428 - val_loss: 0.6174 - val_acc: 0.8116\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1627 - acc: 0.9419 - val_loss: 0.5766 - val_acc: 0.8193\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1633 - acc: 0.9433 - val_loss: 0.5359 - val_acc: 0.8283\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1557 - acc: 0.9450 - val_loss: 0.5595 - val_acc: 0.8262\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1536 - acc: 0.9457 - val_loss: 0.5776 - val_acc: 0.8180\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1565 - acc: 0.9447 - val_loss: 0.5247 - val_acc: 0.8295\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1477 - acc: 0.9480 - val_loss: 0.5782 - val_acc: 0.8121\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1494 - acc: 0.9473 - val_loss: 0.5350 - val_acc: 0.8380\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1507 - acc: 0.9480 - val_loss: 0.6002 - val_acc: 0.8180\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1447 - acc: 0.9492 - val_loss: 0.5576 - val_acc: 0.8274\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1483 - acc: 0.9480 - val_loss: 0.5306 - val_acc: 0.8325\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1462 - acc: 0.9487 - val_loss: 0.5445 - val_acc: 0.8335\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1392 - acc: 0.9510 - val_loss: 0.5861 - val_acc: 0.8265\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1404 - acc: 0.9496 - val_loss: 0.5799 - val_acc: 0.8231\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1417 - acc: 0.9493 - val_loss: 0.5727 - val_acc: 0.8266\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1419 - acc: 0.9496 - val_loss: 0.5855 - val_acc: 0.8216\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1375 - acc: 0.9510 - val_loss: 0.5821 - val_acc: 0.8225\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1366 - acc: 0.9513 - val_loss: 0.5975 - val_acc: 0.8196\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1341 - acc: 0.9528 - val_loss: 0.5771 - val_acc: 0.8219\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1366 - acc: 0.9517 - val_loss: 0.5622 - val_acc: 0.8308\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1344 - acc: 0.9522 - val_loss: 0.5606 - val_acc: 0.8346\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1303 - acc: 0.9545 - val_loss: 0.5691 - val_acc: 0.8292\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1318 - acc: 0.9539 - val_loss: 0.5677 - val_acc: 0.8200\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1292 - acc: 0.9539 - val_loss: 0.5718 - val_acc: 0.8315\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1282 - acc: 0.9555 - val_loss: 0.5640 - val_acc: 0.8302\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1270 - acc: 0.9557 - val_loss: 0.5956 - val_acc: 0.8344\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1251 - acc: 0.9560 - val_loss: 0.6334 - val_acc: 0.8125\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1247 - acc: 0.9561 - val_loss: 0.5778 - val_acc: 0.8263\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1246 - acc: 0.9565 - val_loss: 0.6098 - val_acc: 0.8164\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1222 - acc: 0.9583 - val_loss: 0.6043 - val_acc: 0.8233\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1266 - acc: 0.9562 - val_loss: 0.6142 - val_acc: 0.8201\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1195 - acc: 0.9576 - val_loss: 0.5730 - val_acc: 0.8298\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1184 - acc: 0.9579 - val_loss: 0.5531 - val_acc: 0.8386\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1190 - acc: 0.9590 - val_loss: 0.6975 - val_acc: 0.8036\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1132 - acc: 0.9607 - val_loss: 0.5738 - val_acc: 0.8320\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1165 - acc: 0.9595 - val_loss: 0.5695 - val_acc: 0.8289\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1127 - acc: 0.9608 - val_loss: 0.6242 - val_acc: 0.8280\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1154 - acc: 0.9601 - val_loss: 0.5612 - val_acc: 0.8303\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1153 - acc: 0.9602 - val_loss: 0.5808 - val_acc: 0.8384\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1146 - acc: 0.9593 - val_loss: 0.5819 - val_acc: 0.8332\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1150 - acc: 0.9599 - val_loss: 0.5745 - val_acc: 0.8216\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1129 - acc: 0.9603 - val_loss: 0.5750 - val_acc: 0.8378\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1144 - acc: 0.9603 - val_loss: 0.6001 - val_acc: 0.8239\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1092 - acc: 0.9627 - val_loss: 0.5521 - val_acc: 0.8334\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1042 - acc: 0.9633 - val_loss: 0.5708 - val_acc: 0.8392\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1121 - acc: 0.9600 - val_loss: 0.5862 - val_acc: 0.8331\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1060 - acc: 0.9627 - val_loss: 0.6296 - val_acc: 0.8125\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1015 - acc: 0.9644 - val_loss: 0.5842 - val_acc: 0.8385\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1101 - acc: 0.9613 - val_loss: 0.5985 - val_acc: 0.8273\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1025 - acc: 0.9638 - val_loss: 0.5943 - val_acc: 0.8273\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1047 - acc: 0.9635 - val_loss: 0.6070 - val_acc: 0.8280\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1041 - acc: 0.9639 - val_loss: 0.6448 - val_acc: 0.8330\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1064 - acc: 0.9627 - val_loss: 0.5974 - val_acc: 0.8247\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1039 - acc: 0.9638 - val_loss: 0.5620 - val_acc: 0.8412\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1054 - acc: 0.9637 - val_loss: 0.5751 - val_acc: 0.8293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4cb43d59d0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit_generator(datagen.flow(X_train, Y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        samples_per_epoch=X_train.shape[0],\n",
    "                        nb_epoch=100,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1027 - acc: 0.9640 - val_loss: 0.6153 - val_acc: 0.8279\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1033 - acc: 0.9640 - val_loss: 0.5529 - val_acc: 0.8394\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0947 - acc: 0.9676 - val_loss: 0.6060 - val_acc: 0.8284\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.1010 - acc: 0.9654 - val_loss: 0.6410 - val_acc: 0.8325\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0977 - acc: 0.9662 - val_loss: 0.6532 - val_acc: 0.8220\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0968 - acc: 0.9667 - val_loss: 0.6201 - val_acc: 0.8291\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0994 - acc: 0.9653 - val_loss: 0.5922 - val_acc: 0.8387\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0961 - acc: 0.9672 - val_loss: 0.5920 - val_acc: 0.8354\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0956 - acc: 0.9669 - val_loss: 0.5981 - val_acc: 0.8352\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0989 - acc: 0.9650 - val_loss: 0.5650 - val_acc: 0.8331\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0907 - acc: 0.9682 - val_loss: 0.6591 - val_acc: 0.8218\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0919 - acc: 0.9679 - val_loss: 0.6984 - val_acc: 0.8192\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0900 - acc: 0.9687 - val_loss: 0.5960 - val_acc: 0.8404\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0933 - acc: 0.9678 - val_loss: 0.5971 - val_acc: 0.8318\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0915 - acc: 0.9685 - val_loss: 0.7382 - val_acc: 0.8072\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0954 - acc: 0.9668 - val_loss: 0.5595 - val_acc: 0.8364\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0924 - acc: 0.9680 - val_loss: 0.6059 - val_acc: 0.8216\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0898 - acc: 0.9683 - val_loss: 0.5818 - val_acc: 0.8333\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0892 - acc: 0.9686 - val_loss: 0.6233 - val_acc: 0.8214\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0925 - acc: 0.9680 - val_loss: 0.5917 - val_acc: 0.8311\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0863 - acc: 0.9700 - val_loss: 0.5989 - val_acc: 0.8374\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0915 - acc: 0.9681 - val_loss: 0.6224 - val_acc: 0.8292\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0915 - acc: 0.9683 - val_loss: 0.6475 - val_acc: 0.8190\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0826 - acc: 0.9713 - val_loss: 0.7016 - val_acc: 0.8191\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0910 - acc: 0.9684 - val_loss: 0.6734 - val_acc: 0.8080\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0832 - acc: 0.9711 - val_loss: 0.6252 - val_acc: 0.8309\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0903 - acc: 0.9693 - val_loss: 0.6530 - val_acc: 0.8320\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0860 - acc: 0.9711 - val_loss: 0.5890 - val_acc: 0.8371\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0872 - acc: 0.9702 - val_loss: 0.5949 - val_acc: 0.8392\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0872 - acc: 0.9699 - val_loss: 0.6395 - val_acc: 0.8195\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0856 - acc: 0.9700 - val_loss: 0.6393 - val_acc: 0.8258\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0818 - acc: 0.9712 - val_loss: 0.6443 - val_acc: 0.8272\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0848 - acc: 0.9709 - val_loss: 0.6302 - val_acc: 0.8366\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0865 - acc: 0.9702 - val_loss: 0.5898 - val_acc: 0.8379\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0867 - acc: 0.9700 - val_loss: 0.6076 - val_acc: 0.8347\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0884 - acc: 0.9696 - val_loss: 0.6062 - val_acc: 0.8321\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0832 - acc: 0.9708 - val_loss: 0.5842 - val_acc: 0.8325\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0825 - acc: 0.9715 - val_loss: 0.6979 - val_acc: 0.8229\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0806 - acc: 0.9715 - val_loss: 0.5833 - val_acc: 0.8379\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0782 - acc: 0.9730 - val_loss: 0.6245 - val_acc: 0.8368\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0816 - acc: 0.9721 - val_loss: 0.6428 - val_acc: 0.8301\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0779 - acc: 0.9734 - val_loss: 0.6517 - val_acc: 0.8273\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0805 - acc: 0.9727 - val_loss: 0.6471 - val_acc: 0.8283\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0778 - acc: 0.9738 - val_loss: 0.6060 - val_acc: 0.8360\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0772 - acc: 0.9734 - val_loss: 0.6099 - val_acc: 0.8349\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0787 - acc: 0.9724 - val_loss: 0.6646 - val_acc: 0.8286\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0762 - acc: 0.9735 - val_loss: 0.5836 - val_acc: 0.8349\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0750 - acc: 0.9742 - val_loss: 0.6149 - val_acc: 0.8395\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0744 - acc: 0.9740 - val_loss: 0.6773 - val_acc: 0.8292\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0749 - acc: 0.9748 - val_loss: 0.6490 - val_acc: 0.8264\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0754 - acc: 0.9747 - val_loss: 0.6102 - val_acc: 0.8433\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0797 - acc: 0.9733 - val_loss: 0.6293 - val_acc: 0.8288\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0765 - acc: 0.9742 - val_loss: 0.5943 - val_acc: 0.8435\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0795 - acc: 0.9731 - val_loss: 0.6248 - val_acc: 0.8436\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0741 - acc: 0.9748 - val_loss: 0.6566 - val_acc: 0.8320\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0740 - acc: 0.9751 - val_loss: 0.7273 - val_acc: 0.8118\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0760 - acc: 0.9733 - val_loss: 0.6252 - val_acc: 0.8341\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0748 - acc: 0.9745 - val_loss: 0.6009 - val_acc: 0.8424\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0770 - acc: 0.9739 - val_loss: 0.6277 - val_acc: 0.8312\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0730 - acc: 0.9745 - val_loss: 0.6464 - val_acc: 0.8286\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0707 - acc: 0.9759 - val_loss: 0.6372 - val_acc: 0.8350\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0724 - acc: 0.9750 - val_loss: 0.6478 - val_acc: 0.8290\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0712 - acc: 0.9761 - val_loss: 0.6260 - val_acc: 0.8368\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0730 - acc: 0.9756 - val_loss: 0.6812 - val_acc: 0.8248\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0694 - acc: 0.9765 - val_loss: 0.6430 - val_acc: 0.8400\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0731 - acc: 0.9748 - val_loss: 0.6597 - val_acc: 0.8350\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0697 - acc: 0.9757 - val_loss: 0.6535 - val_acc: 0.8275\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0713 - acc: 0.9760 - val_loss: 0.6377 - val_acc: 0.8305\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0719 - acc: 0.9750 - val_loss: 0.5981 - val_acc: 0.8381\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0689 - acc: 0.9753 - val_loss: 0.6093 - val_acc: 0.8329\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0696 - acc: 0.9766 - val_loss: 0.6453 - val_acc: 0.8356\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0681 - acc: 0.9764 - val_loss: 0.6372 - val_acc: 0.8331\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0653 - acc: 0.9773 - val_loss: 0.6310 - val_acc: 0.8438\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0697 - acc: 0.9759 - val_loss: 0.6713 - val_acc: 0.8345\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0675 - acc: 0.9774 - val_loss: 0.6521 - val_acc: 0.8309\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0672 - acc: 0.9768 - val_loss: 0.6189 - val_acc: 0.8329\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0671 - acc: 0.9771 - val_loss: 0.6107 - val_acc: 0.8287\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0693 - acc: 0.9769 - val_loss: 0.6516 - val_acc: 0.8398\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0674 - acc: 0.9768 - val_loss: 0.6251 - val_acc: 0.8323\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0687 - acc: 0.9772 - val_loss: 0.6350 - val_acc: 0.8326\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0680 - acc: 0.9765 - val_loss: 0.6550 - val_acc: 0.8323\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0675 - acc: 0.9771 - val_loss: 0.6320 - val_acc: 0.8358\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0667 - acc: 0.9776 - val_loss: 0.6632 - val_acc: 0.8305\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0638 - acc: 0.9775 - val_loss: 0.6672 - val_acc: 0.8239\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0650 - acc: 0.9775 - val_loss: 0.6182 - val_acc: 0.8326\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0630 - acc: 0.9785 - val_loss: 0.6560 - val_acc: 0.8270\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0663 - acc: 0.9776 - val_loss: 0.6870 - val_acc: 0.8231\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0631 - acc: 0.9785 - val_loss: 0.6291 - val_acc: 0.8304\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0645 - acc: 0.9785 - val_loss: 0.7088 - val_acc: 0.8241\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0643 - acc: 0.9782 - val_loss: 0.6027 - val_acc: 0.8415\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0666 - acc: 0.9774 - val_loss: 0.6386 - val_acc: 0.8319\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0632 - acc: 0.9779 - val_loss: 0.6181 - val_acc: 0.8394\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0646 - acc: 0.9780 - val_loss: 0.7088 - val_acc: 0.8210\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0664 - acc: 0.9773 - val_loss: 0.6513 - val_acc: 0.8304\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0625 - acc: 0.9787 - val_loss: 0.6935 - val_acc: 0.8202\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0632 - acc: 0.9788 - val_loss: 0.6276 - val_acc: 0.8429\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0625 - acc: 0.9792 - val_loss: 0.6327 - val_acc: 0.8363\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0633 - acc: 0.9783 - val_loss: 0.6466 - val_acc: 0.8337\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0653 - acc: 0.9780 - val_loss: 0.6399 - val_acc: 0.8336\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 105s - loss: 0.0606 - acc: 0.9791 - val_loss: 0.6419 - val_acc: 0.8322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4cb43d5310>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit_generator(datagen.flow(X_train, Y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        samples_per_epoch=X_train.shape[0],\n",
    "                        nb_epoch=100,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using-learning-rate-schedules-deep-learning-models-python-keras/\n",
    "# http://machinelearningmastery.com/using-learning-rate-schedules-deep-learning-models-python-keras/\n",
    "\n",
    "import keras as keras\n",
    "\n",
    "# make model\n",
    "def make_model_xavier_init():\n",
    "  model = Sequential()\n",
    "  model.add(Dropout(0.2, input_shape=(3, 32, 32)))\n",
    "  model.add(Convolution2D(96, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001), init=\"glorot_normal\" ))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(96, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001), init=\"glorot_normal\"))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(96, 3, 3, border_mode=\"same\", subsample=(2,2), W_regularizer=l2(0.001), init=\"glorot_normal\"))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Convolution2D(192, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001), init=\"glorot_normal\"))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(192, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001), init=\"glorot_normal\"))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(192, 3, 3, border_mode=\"same\", subsample=(2,2), W_regularizer=l2(0.001), init=\"glorot_normal\"))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Convolution2D(192, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001), init=\"glorot_normal\"))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(192, 1, 1, border_mode=\"same\", W_regularizer=l2(0.001), init=\"glorot_normal\"))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(10, 1, 1, border_mode=\"same\", W_regularizer=l2(0.001), init=\"glorot_normal\"))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(AveragePooling2D(pool_size=(8, 8), border_mode='valid'))\n",
    "  model.add(Flatten())\n",
    "  model.add(Activation(\"softmax\"))\n",
    "  return model\n",
    "\n",
    "def make_model_temp():\n",
    "  model = Sequential()\n",
    "  model.add(Dropout(0.2, input_shape=(3, 32, 32)))\n",
    "  model.add(Convolution2D(96, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(96, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(96, 3, 3, border_mode=\"same\", subsample=(2,2), W_regularizer=l2(0.001)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Convolution2D(192, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(192, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(192, 3, 3, border_mode=\"same\", subsample=(2,2), W_regularizer=l2(0.001)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Convolution2D(192, 3, 3, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(192, 1, 1, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Convolution2D(10, 1, 1, border_mode=\"same\", W_regularizer=l2(0.001)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(AveragePooling2D(pool_size=(8, 8), border_mode='valid'))\n",
    "  model.add(Flatten())\n",
    "  model.add(Activation(\"softmax\"))\n",
    "  return model\n",
    "\n",
    "# learning rate schedule\n",
    "def lr_decay_schedule(epoch):\n",
    "  if (epoch < 200):    return 0.01\n",
    "  elif (epoch < 250): return 0.001\n",
    "  elif (epoch < 300): return 0.0001\n",
    "  return 0.00001\n",
    "\n",
    "def test4():\n",
    "  \"\"\"\n",
    "  # time based decay\n",
    "  # Compile model\n",
    "  epochs = 50\n",
    "  learning_rate = 0.1\n",
    "  decay_rate = learning_rate / epochs\n",
    "  momentum = 0.8\n",
    "  sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "  \"\"\"\n",
    "\n",
    "  # Make model\n",
    "  #model = make_model_xavier_init()\n",
    "  model = make_model_temp()\n",
    "\n",
    "  # Compile model\n",
    "  sgd = SGD(lr=0.0, momentum=0.9)\n",
    "  model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "  model.summary()\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dropout_138 (Dropout)            (None, 3, 32, 32)     0           dropout_input_45[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_412 (Convolution2D)(None, 96, 32, 32)    2688        dropout_138[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_454 (Activation)      (None, 96, 32, 32)    0           convolution2d_412[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_413 (Convolution2D)(None, 96, 32, 32)    83040       activation_454[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_455 (Activation)      (None, 96, 32, 32)    0           convolution2d_413[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_414 (Convolution2D)(None, 96, 16, 16)    83040       activation_455[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_456 (Activation)      (None, 96, 16, 16)    0           convolution2d_414[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_139 (Dropout)            (None, 96, 16, 16)    0           activation_456[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_415 (Convolution2D)(None, 192, 16, 16)   166080      dropout_139[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_457 (Activation)      (None, 192, 16, 16)   0           convolution2d_415[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_416 (Convolution2D)(None, 192, 16, 16)   331968      activation_457[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_458 (Activation)      (None, 192, 16, 16)   0           convolution2d_416[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_417 (Convolution2D)(None, 192, 8, 8)     331968      activation_458[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_459 (Activation)      (None, 192, 8, 8)     0           convolution2d_417[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_140 (Dropout)            (None, 192, 8, 8)     0           activation_459[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_418 (Convolution2D)(None, 192, 8, 8)     331968      dropout_140[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "activation_460 (Activation)      (None, 192, 8, 8)     0           convolution2d_418[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_419 (Convolution2D)(None, 192, 8, 8)     37056       activation_460[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_461 (Activation)      (None, 192, 8, 8)     0           convolution2d_419[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_420 (Convolution2D)(None, 10, 8, 8)      1930        activation_461[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_462 (Activation)      (None, 10, 8, 8)      0           convolution2d_420[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_45 (AveragePooli(None, 10, 1, 1)      0           activation_462[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_45 (Flatten)             (None, 10)            0           averagepooling2d_45[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "activation_463 (Activation)      (None, 10)            0           flatten_45[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 1369738\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "GraphDef argument to Extend includes node 'Variable_697/initial_value', which was created by a previous call to Create or Extend in this session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-b7ca194fcbdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                      \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                      \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                      validation_data=(X_test, Y_test))\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0;31m# get trainable weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0mtrainable_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_trainable_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m             \u001b[0mtraining_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m             \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/optimizers.pyc\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, params, constraints, loss)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# momentum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m  \u001b[0;31m# velocity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     '''\n\u001b[0;32m--> 695\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, session)\u001b[0m\n\u001b[1;32m    435\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m`\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[0;32m--> 437\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minitialized_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \"\"\"\n\u001b[0;32m--> 555\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3496\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3497\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3498\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 372\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    373\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 636\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    637\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 708\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    709\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: GraphDef argument to Extend includes node 'Variable_697/initial_value', which was created by a previous call to Create or Extend in this session."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#model4 = test4()\n",
    "model4 = make_model(\"sgd\")\n",
    "\n",
    "# Fit the model\n",
    "datagen4 = make_detagen()\n",
    "model4.fit_generator(datagen4.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                      samples_per_epoch=X_train.shape[0],\n",
    "                      nb_epoch=350,\n",
    "                      # learning schedule callback\n",
    "                      #callbacks = [keras.callbacks.LearningRateScheduler(lr_decay_schedule)],\n",
    "                      validation_data=(X_test, Y_test))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#op = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "datagen4 = make_detagen()\n",
    "model4 = make_model(\"sgd\")\n",
    "model4.fit_generator(datagen4.flow(X_train, Y_train,\n",
    "                                   batch_size=batch_size),\n",
    "                     samples_per_epoch=X_train.shape[0],\n",
    "                     nb_epoch=nb_epoch,\n",
    "                     validation_data=(X_test, Y_test))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/e50200c82d6f3a5143e7b206a0ab2451"
  },
  "gist": {
   "data": {
    "description": "keras-cifar10 dropout",
    "public": false
   },
   "id": "e50200c82d6f3a5143e7b206a0ab2451"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
